# -*- coding: utf-8 -*-
"""CropTypePrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sEZjhh4CV4oQzjJOybCGuurUk4babM55
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)
COLAB = True

from google.colab import files
uploaded = files.upload()

"""IMPORTING THE NECESSARY LIBRARIES"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd # data analysis
import numpy as np # linear algebra

#import libraries for data visualization
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

from sklearn.metrics import classification_report
from sklearn import metrics
from sklearn.model_selection import cross_val_score
import warnings
warnings.filterwarnings('ignore')

#Reading the dataset
crop_type = pd.read_csv('crops.csv')
crop_type.head()

"""**EXPLORING THE DATASET (EDA)**"""

#shows the number of rows and columns respectively.
crop_type.shape

#shows the number of values for each of the crop type
crop_type['crop'].value_counts()

#shows the number of missing values
crop_type.isnull().sum()

#shows the diferent types of crops for prediction in our data set
crop_type['crop'].unique()

#Shows all the features column
crop_type.columns

#shows the generate descriptive statistics that summarize the central tendency, dispersion and shape of a dataset's distribution
crop_type.describe()

"""DATA VISUALIZATION"""

plt.figure(figsize=(10,5))
plt.subplot(1, 2, 1)
sns.distplot(crop_type['temperature'],color="red",bins=15,hist_kws={'alpha':0.5})

plt.figure(figsize=(12,5))
plt.subplot(1, 2, 2)
sns.distplot(crop_type['ph'],color="green",bins=15,hist_kws={'alpha':0.5})

plt.figure(figsize=(12,5))
plt.subplot(1, 2, 2)
sns.distplot(crop_type['rainfall'],color="blue",bins=15,hist_kws={'alpha':0.5})

plt.figure(figsize=(12,5))
plt.subplot(1, 2, 2)
sns.distplot(crop_type['humidity'],color="orange",bins=15,hist_kws={'alpha':0.5})

plt.figure(figsize=(12,5))
plt.subplot(1, 2, 2)
sns.distplot(crop_type['N'],color="purple",bins=15,hist_kws={'alpha':0.5})

plt.figure(figsize=(12,5))
plt.subplot(1, 2, 2)
sns.distplot(crop_type['P'],color="brown",bins=15,hist_kws={'alpha':0.5})

plt.figure(figsize=(12,5))
plt.subplot(1, 2, 2)
sns.distplot(crop_type['K'],color="black",bins=15,hist_kws={'alpha':0.5})

#comparing all elements by visualization
sns.boxplot(data=crop_type.loc[:, ['N', 'P', 'K']])

#comparing all weather conditions by visualization
sns.boxplot(data=crop_type.loc[:, ['temperature', 'humidity', 'ph', 'rainfall']])

fig, ax = plt.subplots(1, 1, figsize=(12, 7))
sns.heatmap(crop_type.corr(), annot=True,cmap='viridis')
ax.set(xlabel='features')
ax.set(ylabel='features')

plt.title('Correlation of all the features', fontsize = 15, c='black')
plt.show()

#dropping the dependent variable
features = crop_type[['N', 'P','K','temperature', 'humidity', 'ph', 'rainfall']]
label = crop_type['crop']

features.head(3)

label.head(3)

#splitting the data into train and test
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(features,label,test_size = 0.2,random_state =2)
x_train.shape

x_test.shape

"""**MODEL BUILDING**"""

#importing Random Forest Classifier
from sklearn.ensemble import RandomForestClassifier

#fitting the model
RF = RandomForestClassifier()
RF.fit(x_train, y_train)

#showing the training score
score = RF.score(x_train, y_train)
print("Training Score:" , score)

#showing the testing score
score = RF.score(x_test, y_test)
print("Testing Score:" , score)

"""**VALIDATING THE MODEL**"""

# to test the model's ability to predict new data
from sklearn.model_selection import cross_val_score
cv_score = cross_val_score(RF, x_train, y_train, cv=10)
print("Train CV mean score:", cv_score.mean())
cv_score = cross_val_score(RF, x_test, y_test, cv=10)
print("Test CV mean score:", cv_score.mean())

"""VISUALIZING THE MODEL"""

#visualizes and summarizes the performance of the crop model.
from sklearn.metrics import confusion_matrix
y_pred = RF.predict(x_test)
CM = confusion_matrix(y_test, y_pred)
print(CM)

"""SHOWING REPORT OF THE MODEL, HOW MANY PREDICTIONS ARE TRUE FOR FALSE"""

#showing report of the model
from sklearn.metrics import classification_report
class_report = classification_report(y_test, y_pred)
print(class_report)

"""MAKING PREDICTION WITH THE MODEL"""

RF.predict(np.array([[90,	42,	43,	20.879744,	82.002744,	6.502985,  202.935536]]))

RF.predict(np.array([[22.5,	42.0,	90,	69.94673,	37.63917,	1.38173,  10.173529]]))

RF.predict(x_test)

import pickle

FR_pkl_file = 'CRandomForest.pkl'

RF_Model_pkl = open(FR_pkl_file, 'wb')
pickle.dump(RF, RF_Model_pkl)

RF_Model_pkl.close()



"""# New Section"""